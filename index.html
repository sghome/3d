<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Audio Visualization</title>
    
<script src="https://cdn.jsdelivr.net/npm/@tonejs/midi"></script>


    
 <script type="module">
        import * as THREE from "https://cdn.skypack.dev/three@0.136.0";
        import { GLTFLoader } from "https://cdn.skypack.dev/three@0.136.0/examples/jsm/loaders/GLTFLoader.js";
        import { OrbitControls } from "https://cdn.skypack.dev/three@0.136.0/examples/jsm/controls/OrbitControls.js";

        // Configuración de la escena
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Configuración de la luz
        const ambientLight = new THREE.AmbientLight(0xffffff, 1);
        scene.add(ambientLight);

        // Cargar el modelo GLB
        const loader = new GLTFLoader();
        const glbPath = 'https://cdn.glitch.me/764bc5af-2031-4a40-82a5-7a4337618c33/xr.glb';

        loader.load(glbPath, (gltf) => {
            const xrModel = gltf.scene;

            // Ajustar posición y escala según tus necesidades
            xrModel.scale.set(0.1, 0.1, 0.1);
            xrModel.position.set(0, 0, 0);

            scene.add(xrModel);

            // Animación (opcional)
            const animate = function () {
                requestAnimationFrame(animate);

                // Agregar animaciones o actualizaciones aquí si es necesario

                renderer.render(scene, camera);
            };

            // Configuración de la cámara
            camera.position.z = 5;

            // Iniciar la animación
            animate();
        });
    </script>

    <style>
        * {
            box-sizing: border-box;
        }

        html,
        body {
            margin: 0;
            min-height: 100vh;
            overflow: hidden;

            background: repeating-radial-gradient(
                circle at center,
                #444 0 10%,
                #111 10% 20%
            );

            touch-action: none;
        }

        canvas {
            width: 100%;
            height: auto;
            object-fit: contain;
        }
    </style>
    
    
    
    
    
</head>

<body>
    <canvas id="canvas">
    
    
    
 
     
        <script>
        
        var audio, audioContext, audioSrc;
    var analyser, analyserBufferLength;
    var fftSize = 8192;
    var smoothingTimeConstant = 0.65;

    const glCanvas = document.getElementById('canvas');
    const gl = glCanvas.getContext('webgl2');
    const dpr = Math.max(.5, .5 * window.devicePixelRatio);
    const touches = new Map();

    const vertexSource = `#version 300 es
        precision highp float;
        in vec2 position;
        uniform float audioAmplitude;

        void main(void) {
            vec2 newPosition = position + normalize(position) * audioAmplitude * 0.1;
            gl_Position = vec4(newPosition, 0., 1.);
        }
    `;

    const fragmentSource = `#version 300 es
        precision highp float;
        out vec4 fragColor;
        uniform vec2 resolution;
        uniform vec2 touch;
        uniform float time;
        uniform int pointerCount;
        uniform float audioAmplitude;
        uniform vec3 color;
    uniform vec2 offset;
    uniform float scale;
    uniform float rhythmAmplitude;

        

            #define P pointerCount
            #define T mod(10. + time * 2., 300.)
            #define S smoothstep
            #define mouse (touch / resolution)
            #define repeat(a,b) ((fract(a/b-.5)-.5)*b)
            #define lerps(a,b,k) (a*sin(k)+b*(1.-sin(k)))
            
            

    #define TAU 6.2831853
    #define ESN 1.5707963
    #define PI 3.14159265

    mat2 rot(float a) {
        float c = cos(a), s = sin(a);
        return mat2(c, -s, s, c);
    }

    vec3 palette(float k) {
        vec3 a = vec3(.75, .5, .5),
            b = vec3(.5, .5, .75),
            c = vec3(1, 1.8, 1),
            d = vec3(.2, .4, .8);

        return a + b * cos(TAU * (c * k + d));
    }

    float box(vec3 p, vec3 s) {
        p = abs(p) - s;
        return length(max(p, .0)) + min(.0, max(p.x, max(p.y, p.z)));
    }

    float rnd(vec2 uv) {
        return fract(dot(sin(uv * 482.707 + uv.yx * 631.543), vec2(512.544)));
    }

    float rnd(float a) {
        return fract(sin(a * 12.9898) * 43758.5453);
    }

    float curve(float t, float e) {
        t /= e;
        return mix(rnd(floor(t)), rnd(floor(t) + 1.), pow(S(.0, 1., fract(t)), e));
    }

    float map(vec3 p) {
        p.xz = repeat(p.xz, vec2(60));

        for (float i = .0; i < 6.; i++) {
            float t = T * .25 + sin(p.z * .125 + T * .75) * .5;
            p.xz *= rot(t);
            p.xy *= rot(t * 1.25);
            p.xz = abs(p.xz);
            p.xz -= 1.75 + sin(T + p.x * .125) * .75;
        }

        return box(p, vec3(1, 2, .5));
    }

    void cam(inout vec3 p) {
        if (P == 1) {
            p.yz *= rot(-mouse.y * PI + ESN);
            p.xz *= rot(PI - mouse.x * TAU);
        } else {
            float t = T * .05, f = P < 2 ? .0 : curve(t, .04);
            p.xy *= rot(t + f);
            p.xz *= rot(t * 1.3 + f);
        }
    }

    void main(void) {
        vec2 uv = (gl_FragCoord.xy - .5 * resolution.xy) / min(resolution.x, resolution.y);

        vec3 col = vec3(0),
            ro = vec3(0, 0, -30),
            rd = normalize(vec3(uv, 1));

        cam(ro);
        cam(rd);

        vec3 p = ro;

        const float steps = 40., maxd = 200.;
        float dither = mix(.75, 1., rnd(uv));

        for (float i = .0; i < steps; i++) {
            float d = map(p) * dither;

            if (d < 1e-3) {
                d = 1e-1;
            }

            if (d > maxd) {
                d = maxd;
                break;
            }

            p += rd * d;

            col += palette(5e-3 / (.03 + abs(d))) * 5e-3;
            col += palette(5e-3 / (.2 + abs(length(p) - 9.))) * .0125;

            float acc = abs(repeat(p.x, 5.) + max(.0, length(p) - 9.));
            col += vec3(.9, .2, .3) * .01 / (.05 + acc);
            vec2 q = repeat(p.yz, vec2(7));
            float rods = abs(length(q) - .5);
            vec3 st = repeat(p, vec3(7));
            float cubes = abs(box(st, vec3(2)));
            col -= vec3(.5, .9, .2) * 1e-2 / (2e-2 + (P < 2 ? rods : min(rods, cubes)));
        }

        col = max(vec3(.01, .02, .03), col);

        float tr = (2. * T) - length(uv) * 2.;
            col.yz *= rot(tr);
            col.xz *= rot(tr * .7);

            col = abs(col);

            col *= S(1., .0, length(uv));

            col = S(.0, 1., col);
            col = pow(col, vec3(.4545));

            float d = 5e-3 * dot(
                log(length(uv)) - (lerps(.0, 1., -T * .5) * 1e2 + 1e2),
                atan(abs(uv.x), abs(uv.y)) / TAU * 6.
            ) - (sin(T * .5) * .5 + .5) * 2.;

            float e = length(uv) - (sin(T * .5) * 2. + 2.);

            d = mix(d, e, pow(S(.0, 1., sin(T * .2) * .5 + .5), .75));
            d = sin(d * dot(col, col)) - .05;
            d = abs(d);
            d = pow(.1 / d, .125);
            d = max(.0, d);

            col *= d;

            fragColor = vec4(col, 1);
        }
    `;

    let time;
    let buffer;
    let program;
    let touchLoc;
    let resolutionLoc;
    let pointerCountLoc;
    let vertices = [];
    let touching = false;




            let midiInfo; // Variable para almacenar información del MIDI

    async function loadAndProcessMidi(midiFilePath) {
        const response = await fetch(midiFilePath);
        const midiData = await response.arrayBuffer();
        const midi = new Midi(midiData);

        // Guarda la información del MIDI para su uso posterior
        midiInfo = {
            chords: midi.tracks[0].notes.map((note) => note.name),
            tempo: midi.header.tempos[0].bpm,
            // Puedes agregar más propiedades según sea necesario
        };

        // Resto de la función...
    }
            
            

    function resize() {
        const { innerWidth: width, innerHeight: height } = window;
        glCanvas.width = width * dpr;
        glCanvas.height = height * dpr;
        gl.viewport(0, 0, width * dpr, height * dpr);
    }

    function compile(shader, source) {
        gl.shaderSource(shader, source);
        gl.compileShader(shader);

        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            console.error(gl.getShaderInfoLog(shader));
        }
    }

    function setup() {
        const vs = gl.createShader(gl.VERTEX_SHADER);
        const fs = gl.createShader(gl.FRAGMENT_SHADER);

        program = gl.createProgram();

        compile(vs, vertexSource);
        compile(fs, fragmentSource);

        gl.attachShader(program, vs);
        gl.attachShader(program, fs);
        gl.linkProgram(program);

        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
            console.error(gl.getProgramInfoLog(program));
        }

        vertices = [-1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0];

        buffer = gl.createBuffer();

        gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);

        const position = gl.getAttribLocation(program, "position");

        gl.enableVertexAttribArray(position);
        gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);

        time = gl.getUniformLocation(program, "time");
        touchLoc = gl.getUniformLocation(program, "touch");
        pointerCountLoc = gl.getUniformLocation(program, "pointerCount");
        resolutionLoc = gl.getUniformLocation(program, "resolution");
    }

    function draw(now) {
        gl.clearColor(0, 0, 0, 1);
        gl.clear(gl.COLOR_BUFFER_BIT);

        gl.useProgram(program);
        gl.bindBuffer(gl.ARRAY_BUFFER, null);
        gl.bindBuffer(gl.ARRAY_BUFFER, buffer);

        gl.uniform1f(time, now * 0.001);
        gl.uniform2f(touchLoc, ...getTouches());
        gl.uniform1i(pointerCountLoc, touches.size);
        gl.uniform2f(resolutionLoc, glCanvas.width, glCanvas.height);
        gl.drawArrays(gl.TRIANGLES, 0, vertices.length * 0.5);
    }

    function getTouches() {
        if (!touches.size) {
            return [0, 0];
        }

        for (let [id, t] of touches) {
            const result = [dpr * t.clientX, dpr * (innerHeight - t.clientY)];
            return result;
        }
    }

    function loop(now) {
        draw(now);
        requestAnimationFrame(loop);
    }

    function init() {
        setup();
        resize();
        loop(0);

        document.cookie = "parking_session=value; samesite=None; secure";
        document.body.addEventListener('click', initAudio);
    }

    function initAudio() {
        await loadAndProcessMidi('https://sghome.github.io/mp3/go.mid');
        audioSetup('https://sghome.github.io/mp3/go.mp3');
        document.body.removeEventListener('click', initAudio);
    }

    document.body.onload = init;
    window.onresize = resize;

    glCanvas.onpointerdown = e => {
        if (touches.size === 2) touches.clear();
        touching = true;
        touches.set(e.pointerId, e);
    };

    glCanvas.onpointermove = e => {
        if (!touching) return;
        touches.set(e.pointerId, e);
    };

    glCanvas.onpointerup = e => {
        touching = false;
        touches.clear();
    };

    glCanvas.onpointerout = e => {
        if (touches.size === 2) return;
        touching = false;
        touches.clear();
    };

    document.documentElement.onkeyup = e => {
        console.log(e.key);
        if (e.key === "v") {
            touches.set(1, { clientX: 100, clientY: 100 });
            touches.set(2, { clientX: 200, clientY: 200 });
        } else if (e.key === "g") {
            touches.clear();
        }
    };

    function audioSetup(url) {
        audio = new Audio();
        audio.src = url;
        audio.controls = false;
        audio.loop = true;
        audio.autoplay = true;
        audio.crossOrigin = 'anonymous';
        audio.addEventListener('canplaythrough', audioLoaded, false);

        audioContext = new (window.AudioContext || window.webkitAudioContext)();

        analyser = audioContext.createAnalyser();
        analyser.connect(audioContext.destination);
        analyser.smoothingTimeConstant = smoothingTimeConstant;
        analyser.fftSize = fftSize;
        analyserBufferLength = analyser.frequencyBinCount;

        audioSrc = audioContext.createMediaElementSource(audio);
        audioSrc.connect(analyser);
    }

    function audioLoaded() {
        audio.play();
        animate();
    }

    function animate() {
        const dataArray = new Uint8Array(analyserBufferLength);
        analyser.getByteFrequencyData(dataArray);

        // Normaliza la amplitud del audio entre 0 y 1
        const audioAmplitude = dataArray.reduce((a, b) => a + b, 0) / (analyserBufferLength * 255);

        // Actualiza los valores en el shader según la amplitud del audio
        gl.uniform1f(gl.getUniformLocation(program, "audioAmplitude"), audioAmplitude);

        // Modifica la posición y escala de los elementos según la amplitud
        gl.uniform2f(gl.getUniformLocation(program, "offset"), audioAmplitude * 2.0, audioAmplitude * 2.0);
        gl.uniform1f(gl.getUniformLocation(program, "scale"), 1.0 + audioAmplitude);

        // Cambia el color en función de la amplitud
        const color = getColorFromAmplitude(audioAmplitude);
        gl.uniform3f(gl.getUniformLocation(program, "color"), color[0], color[1], color[2]);

        // Agrega efectos de sonido adicionales según la amplitud
        playSoundEffect(audioAmplitude);

        // Puedes agregar aquí la lógica para interactuar con el MIDI y actualizar el shader
        interactWithMidi();

        requestAnimationFrame(animate);
    }



// Función para interactuar con el archivo MIDI y actualizar el shader
function interactWithMidi() {
    const currentChordIndex = getCurrentChordIndex();
    const currentChord = midiInfo.chords[currentChordIndex];

    // Obtén el color asociado al acorde
    const chordColor = chordToColor(currentChord);

    // Pasa el color al shader
    gl.uniform3f(gl.getUniformLocation(program, "color"), chordColor[0], chordColor[1], chordColor[2]);

    // Ajusta la posición y escala de los elementos según la frecuencia del acorde
    const chordFrequency = getChordFrequency(currentChord);
    const positionScaleFactor = map(chordFrequency, 0, 1, 0.5, 2.0);
    gl.uniform2f(gl.getUniformLocation(program, "offset"), audioAmplitude * positionScaleFactor, audioAmplitude * positionScaleFactor);
    gl.uniform1f(gl.getUniformLocation(program, "scale"), 1.0 + audioAmplitude);

    // Genera ritmo según el tempo del MIDI
    const tempo = midiInfo.tempo;
    const beatsPerMinute = tempo;
    const beatsPerSecond = beatsPerMinute / 60;
    const secondsPerBeat = 1 / beatsPerSecond;
    const rhythmAmplitude = Math.sin(audioContext.currentTime * 2 * Math.PI * beatsPerSecond);

    // Utiliza rhythmAmplitude para modular otras propiedades del shader
    gl.uniform1f(gl.getUniformLocation(program, "rhythmAmplitude"), rhythmAmplitude);

    // Puedes ajustar otras propiedades del shader según tu lógica
    // por ejemplo, la intensidad de efectos visuales o la velocidad de animación
    // gl.uniform1f(gl.getUniformLocation(program, "otraPropiedad"), rhythmAmplitude * 0.5);

    // Puedes agregar más lógica según sea necesario
}




            function getCurrentChordIndex() {
    const currentTime = audioContext.currentTime;
    const beatsPerMinute = midiInfo.tempo;
    const beatsPerSecond = beatsPerMinute / 60;
    const secondsPerBeat = 1 / beatsPerSecond;
    const totalBeats = currentTime / secondsPerBeat;

    // Ahora, puedes calcular el índice del acorde actual
    const currentChordIndex = Math.floor(totalBeats) % midiInfo.chords.length;

    return currentChordIndex;
}




            function chordToColor(chord) {
    // Lógica para asignar colores a los acordes
    // Puedes usar el chord wheel o algún otro método
    // Ajusta los valores de r, g, b según tu preferencia
    const r = 1.0;
    const g = 0.5;
    const b = 0.2;

    return [r, g, b];
}



            function interactWithMidi() {
    const currentChordIndex = getCurrentChordIndex();
    const currentChord = midiInfo.chords[currentChordIndex];

    // Obtén el color asociado al acorde
    const chordColor = chordToColor(currentChord);

    // Pasa el color al shader
    gl.uniform3f(gl.getUniformLocation(program, "color"), chordColor[0], chordColor[1], chordColor[2]);

    // Ajusta la posición y escala de los elementos según la frecuencia del acorde
    const chordFrequency = getChordFrequency(currentChord);
    const positionScaleFactor = map(chordFrequency, 0, 1, 0.5, 2.0);
    gl.uniform2f(gl.getUniformLocation(program, "offset"), audioAmplitude * positionScaleFactor, audioAmplitude * positionScaleFactor);
    gl.uniform1f(gl.getUniformLocation(program, "scale"), 1.0 + audioAmplitude);

    // Genera ritmo según el tempo del MIDI
    const tempo = midiInfo.tempo;
    const beatsPerMinute = tempo;
    const beatsPerSecond = beatsPerMinute / 60;
    const secondsPerBeat = 1 / beatsPerSecond;
    const rhythmAmplitude = Math.sin(audioContext.currentTime * 2 * Math.PI * beatsPerSecond);

    // Utiliza rhythmAmplitude para modular otras propiedades del shader
    gl.uniform1f(gl.getUniformLocation(program, "rhythmAmplitude"), rhythmAmplitude);

    // Puedes ajustar otras propiedades del shader según tu lógica
    // por ejemplo, la intensidad de efectos visuales o la velocidad de animación
    // gl.uniform1f(gl.getUniformLocation(program, "otraPropiedad"), rhythmAmplitude * 0.5);

    // Puedes agregar más lógica según sea necesario
}

function getChordFrequency(chord) {
    // Lógica para determinar la frecuencia del acorde
    // Puedes mapear los acordes a valores de frecuencia según tus preferencias
    // Ajusta los valores según tu visión creativa
    return map(chord.intensity, 0, 1, 0.2, 0.8);
}

function map(value, inMin, inMax, outMin, outMax) {
    // Función de mapeo para ajustar valores de un rango a otro
    return (value - inMin) * (outMax - outMin) / (inMax - inMin) + outMin;
}

// Resto del código...



            

function getColorFromAmplitude(amplitude) {
        // Ajusta los valores de color según la amplitud del audio
        const r = 0.5 + amplitude * 0.5;
        const g = 0.2 + amplitude * 0.8;
        const b = 0.1 + amplitude * 0.9;

        return [r, g, b];
    }

    function playSoundEffect(amplitude) {
    // Ajusta la reproducción de efectos de sonido según la amplitud
    const volume = amplitude * 2.0; // Ajusta el volumen según la amplitud

    // Ejemplo: reproducir un efecto de sonido adicional
    // Comenta o elimina la línea siguiente para evitar cargar el recurso específico
    // if (volume > 0.5) {
    //     playAdditionalSound('https://ejemplo.com/efecto-adicional.mp3', volume);
    // }

    // Puedes agregar más lógica y efectos de sonido según tus necesidades
}

function playAdditionalSound(url, volume) {
    const additionalAudio = new Audio(url);
    additionalAudio.volume = Math.min(1.0, volume); // Ajusta el volumen entre 0 y 1
    additionalAudio.play();
}
    
    
  </script>
  
 </canvas>


</body>

</html>
